# Nanoparticles_Toxicity
### **üîπ Introduction**

This project explores **nanoparticle toxicity classification** using a dataset containing various nanoparticles and their physicochemical properties. The dataset includes features such as **core size, hydrosize, surface charge, surface area, Ec (energy-related property), exposure time, dosage, and number of oxygen atoms**. The final column represents toxicity, where **1 indicates toxic** and **0 indicates non-toxic**.

---

### **üîπ Methods**

After loading the dataset, **preprocessing** was performed to ensure compatibility with machine learning models.

1Ô∏è‚É£ **One-Hot Encoding** was applied to transform the categorical **nanoparticle (NPs) column** into a numerical format, making it suitable for machine learning. Since One-Hot Encoding produces only **0s and 1s**, these values remained unchanged even after normalization.

2Ô∏è‚É£ The **target column (toxicity label)** was separated from the feature set, and the dataset was split into **training (80%) and testing (20%) sets**.

3Ô∏è‚É£ **Feature Normalization** was applied to scale all numerical features between **0 and 1**, ensuring models learn effectively without bias toward larger values. The processed data was then converted back into a dataframe.

4Ô∏è‚É£ A **custom evaluation function** was implemented to compute **accuracy, recall, precision, and F1-score** for performance comparison.

5Ô∏è‚É£ Machine learning models including **XGBoost, SVM, Random Forest, Decision Tree, Logistic Regression, and ANN (Artificial Neural Network)** were trained and evaluated.

---

### **üîπ Results and Findings**

The **Model Performance Heatmap** indicates that **no major overfitting** was observed. Most models exhibited **similar Train and Test F1-Scores**, demonstrating good generalization to new data. While **XGBoost and Random Forest showed slight overfitting** (Train ‚âà 0.99 vs. Test ‚âà 0.96), the gap was minimal and **not concerning**. Other models, such as **Decision Tree, SVM, ANN, and Logistic Regression**, performed well without signs of memorization, suggesting a strong balance between learning and generalization.

The **Confusion Matrix** provided insight into False Negatives (FN), False Positives (FP), True Positives (TP), and True Negatives (TN) for each model. **XGBoost, Random Forest, and ANN performed best**, with **0 or 1 FN cases**, indicating high reliability in detecting toxic nanoparticles. While **Logistic Regression** showed only one FN, its high FP count (32) reduced its reliability for accurate predictions. SVM, in contrast, demonstrated weaker performance, failing to minimize both FN and FP errors compared to other models.

Finally, a **Feature Importance Plot** was generated for tree-based models (**XGBoost, Random Forest, and Decision Tree**), as **SVM and ANN** do not provide direct feature importance scores. This analysis revealed that **Number of Oxygen atoms and Dosage** were the most influential features affecting toxicity. Additionally, models such as Random Forest, XGBoost, and Logistic Regression indicated that the **TiO‚ÇÇ nanoparticle is toxic** within a probability range of approximately 6% to 36%.

---

### **üîπ Conclusion**

The results suggest that **XGBoost, Random Forest, and ANN are the most effective models for nanoparticle toxicity classification** due to their ability to **minimize False Negatives while maintaining high accuracy**. The findings highlight that **dosage and oxygen content** play a crucial role in determining toxicity, making them key factors for future research and regulatory assessments.

## ‚úâ Contact
If you have any questions or feedback, feel free to reach out!
- **LinkedIn:** www.linkedin.com/in/elaheh-p-9918432a6

 **If you find this project useful, please ‚≠ê star the repository!** ‚≠ê
